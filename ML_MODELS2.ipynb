{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/taciturn02/CreditCardFruadDetection/blob/main/ML_MODELS2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {
        "id": "af6ytPke5kNc"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 237,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CHLz3LRP5prS",
        "outputId": "7c0e2e05-40ac-4dbc-ebbd-441f24d2e23d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 238,
      "metadata": {
        "id": "g5ADbImS5rSZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score,classification_report,confusion_matrix,f1_score,roc_auc_score\n",
        "from sklearn.model_selection import KFold,cross_val_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 239,
      "metadata": {
        "id": "IgjdfA3I51G0"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"/content/drive/MyDrive/CreditCard_DataSet/randomUndersammpledData.csv\")\n",
        "train_df2 = pd.read_csv(\"/content/drive/MyDrive/CreditCard_DataSet/randomOversampledData.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 240,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOu74PO46VZI",
        "outputId": "7ce470eb-ccab-4c64-fd4f-d022b7f3bef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4290 entries, 0 to 4289\n",
            "Data columns (total 14 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   merchant    4290 non-null   int64  \n",
            " 1   category    4290 non-null   int64  \n",
            " 2   amt         4290 non-null   float64\n",
            " 3   gender      4290 non-null   int64  \n",
            " 4   lat         4290 non-null   float64\n",
            " 5   long        4290 non-null   float64\n",
            " 6   city_pop    4290 non-null   int64  \n",
            " 7   merch_lat   4290 non-null   float64\n",
            " 8   merch_long  4290 non-null   float64\n",
            " 9   is_fraud    4290 non-null   int64  \n",
            " 10  hour        4290 non-null   int64  \n",
            " 11  day         4290 non-null   int64  \n",
            " 12  month       4290 non-null   int64  \n",
            " 13  age_cust    4290 non-null   int64  \n",
            "dtypes: float64(5), int64(9)\n",
            "memory usage: 469.3 KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1107148 entries, 0 to 1107147\n",
            "Data columns (total 14 columns):\n",
            " #   Column      Non-Null Count    Dtype  \n",
            "---  ------      --------------    -----  \n",
            " 0   merchant    1107148 non-null  int64  \n",
            " 1   category    1107148 non-null  int64  \n",
            " 2   amt         1107148 non-null  float64\n",
            " 3   gender      1107148 non-null  int64  \n",
            " 4   lat         1107148 non-null  float64\n",
            " 5   long        1107148 non-null  float64\n",
            " 6   city_pop    1107148 non-null  int64  \n",
            " 7   merch_lat   1107148 non-null  float64\n",
            " 8   merch_long  1107148 non-null  float64\n",
            " 9   is_fraud    1107148 non-null  int64  \n",
            " 10  hour        1107148 non-null  int64  \n",
            " 11  day         1107148 non-null  int64  \n",
            " 12  month       1107148 non-null  int64  \n",
            " 13  age_cust    1107148 non-null  int64  \n",
            "dtypes: float64(5), int64(9)\n",
            "memory usage: 118.3 MB\n"
          ]
        }
      ],
      "source": [
        "train_df.info()\n",
        "train_df2.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfQBiDZCBgAo"
      },
      "source": [
        "Split data into target and features"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n"
      ],
      "metadata": {
        "id": "ZEWM_o_8Heq6"
      },
      "execution_count": 241,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 242,
      "metadata": {
        "id": "miajjFtJBfgr"
      },
      "outputs": [],
      "source": [
        "XX = train_df.drop(columns='is_fraud', axis=1)\n",
        "YY = train_df['is_fraud']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "X= scaler.fit_transform(XX)\n"
      ],
      "metadata": {
        "id": "-0nweu3YHSbz"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.mean(axis=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgkrUYMZIiuc",
        "outputId": "554731d0-68d5-44c4-efe6-70f1a1b02d5f"
      },
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.48958864, 0.52404519, 0.11581572, 0.45734266, 0.40928096,\n",
              "       0.77038171, 0.02866145, 0.4132861 , 0.764363  , 0.5854059 ,\n",
              "       0.49273504, 0.5506216 , 0.39971222])"
            ]
          },
          "metadata": {},
          "execution_count": 244
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 245,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bz21EdyVByuz",
        "outputId": "275c1ff5-e881-411b-a860-d7e58f3a69b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.6632948 , 0.30769231, 0.02165597, ..., 0.66666667, 1.        ,\n",
              "        0.37037037],\n",
              "       [0.34104046, 0.        , 0.0198289 , ..., 1.        , 0.        ,\n",
              "        0.43209877],\n",
              "       [0.03323699, 0.76923077, 0.01309331, ..., 0.66666667, 0.33333333,\n",
              "        0.54320988],\n",
              "       ...,\n",
              "       [0.64017341, 0.84615385, 0.40452909, ..., 0.83333333, 1.        ,\n",
              "        0.56790123],\n",
              "       [0.04190751, 0.30769231, 0.11229626, ..., 0.83333333, 1.        ,\n",
              "        0.56790123],\n",
              "       [0.40606936, 0.61538462, 0.29816203, ..., 0.83333333, 1.        ,\n",
              "        0.56790123]])"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ],
      "source": [
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initalize K-Fold Cross Validation"
      ],
      "metadata": {
        "id": "f8hL3QBO01hA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n"
      ],
      "metadata": {
        "id": "_INbm4g9001_"
      },
      "execution_count": 246,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = {\n",
        "    'accuracy': accuracy_score,\n",
        "    'precision': precision_score,\n",
        "    'f1_macro' : f1_score,\n",
        "    'recall': recall_score,\n",
        "    'roc_auc': roc_auc_score,\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "dcv5QLt83err"
      },
      "execution_count": 247,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_testing1(estimator):\n",
        "    ## Prediction on data\n",
        "    y_preds = estimator.predict(X_test)\n",
        "\n",
        "    ##Print accuracy score\n",
        "    print(\"Accuracy Score on UnderSampled Test Data: \",accuracy_score(Y_test,y_preds))\n",
        "\n",
        "    ## Print classification report\n",
        "    print(\"\\nConfussion Matrix  of UnderSampled Test Data:\\n \" ,confusion_matrix(Y_test ,y_preds),\"\\n\")\n",
        "\n",
        "    ## Check confusion matrix\n",
        "    print(\"classification_report of UnderSampled Test Data: \\n\\n\",classification_report(Y_test ,y_preds))\n"
      ],
      "metadata": {
        "id": "zNoEcJVO4qX7"
      },
      "execution_count": 248,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_testing11(estimator):\n",
        "    ## Prediction on data\n",
        "    y_preds = estimator.predict(X_train)\n",
        "\n",
        "    ##Print accuracy score\n",
        "    print(\"Accuracy Score on UnderSampled Train Data: \",accuracy_score(Y_train,y_preds))\n",
        "\n",
        "    ## Print classification report\n",
        "    print(\"\\nConfussion Matrix  of UnderSampled Train Data:\\n \" ,confusion_matrix(Y_train ,y_preds),\"\\n\")\n",
        "\n",
        "    ## Check confusion matrix\n",
        "    print(\"classification_report of UnderSampled Train Data: \\n\\n\",classification_report(Y_train ,y_preds))"
      ],
      "metadata": {
        "id": "jkME1m1k4q_v"
      },
      "execution_count": 249,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoSDeVjrQ6fn"
      },
      "source": [
        "##LOGISTIC REGRESSION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = LogisticRegression()\n"
      ],
      "metadata": {
        "id": "eDBacxF_1ai6"
      },
      "execution_count": 250,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = {}\n",
        "for metric_name, metric_func in metrics.items():\n",
        "    scores = cross_val_score(model, X, Y, cv=kfold, scoring=metric_name)\n",
        "    evaluation_results[metric_name] = scores.mean()"
      ],
      "metadata": {
        "id": "6iVSug713jPp"
      },
      "execution_count": 251,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_hXv-H6SNfu"
      },
      "source": [
        "MODEL EVALUATION"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for metric_name, score in evaluation_results.items():\n",
        "    print(f\"Mean_{metric_name.capitalize()}: {score}\\n\")"
      ],
      "metadata": {
        "id": "ZT2C_g3R3yrJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4747a2d-8ae1-4014-d400-2e3dd6da1617"
      },
      "execution_count": 252,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean_Accuracy: 0.8435897435897436\n",
            "\n",
            "Mean_Precision: 0.9285865070465888\n",
            "\n",
            "Mean_F1_macro: 0.8419755316601123\n",
            "\n",
            "Mean_Recall: 0.7449889100732412\n",
            "\n",
            "Mean_Roc_auc: 0.8616284067360113\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing Metrics for the best Fold\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YFnh9DCf34At"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')\n",
        "best_fold_index = np.argmax(accuracy_scores)\n"
      ],
      "metadata": {
        "id": "PjlNmccD37J0"
      },
      "execution_count": 253,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Get the train and test indices for the best fold"
      ],
      "metadata": {
        "id": "WJ5XXTYO4Few"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_index, test_index = list(kfold.split(X))[best_fold_index]\n"
      ],
      "metadata": {
        "id": "YWXDH5io4C_L"
      },
      "execution_count": 254,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Split the data into train and test sets for the best fold\n"
      ],
      "metadata": {
        "id": "USTux1Zx4I5E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = X[train_index], X[test_index]\n",
        "Y_train, Y_test = Y[train_index], Y[test_index]"
      ],
      "metadata": {
        "id": "-SO30OCG4G5Y"
      },
      "execution_count": 255,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "HQoRMptu4Dhg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "641a198e-d1ab-483c-dc44-a2c75e888fb1"
      },
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-15 {color: black;background-color: white;}#sk-container-id-15 pre{padding: 0;}#sk-container-id-15 div.sk-toggleable {background-color: white;}#sk-container-id-15 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-15 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-15 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-15 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-15 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-15 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-15 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-15 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-15 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-15 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-15 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-15 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-15 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-15 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-15 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-15 div.sk-item {position: relative;z-index: 1;}#sk-container-id-15 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-15 div.sk-item::before, #sk-container-id-15 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-15 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-15 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-15 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-15 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-15 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-15 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-15 div.sk-label-container {text-align: center;}#sk-container-id-15 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-15 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-15\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_testing1(model)\n"
      ],
      "metadata": {
        "id": "be-3yg3s33LO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a61cfd4-409d-42b7-9a59-5d3e2b522fc4"
      },
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score on UnderSampled Test Data:  0.8601398601398601\n",
            "\n",
            "Confussion Matrix  of UnderSampled Test Data:\n",
            "  [[407  17]\n",
            " [103 331]] \n",
            "\n",
            "classification_report of UnderSampled Test Data: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.96      0.87       424\n",
            "           1       0.95      0.76      0.85       434\n",
            "\n",
            "    accuracy                           0.86       858\n",
            "   macro avg       0.87      0.86      0.86       858\n",
            "weighted avg       0.88      0.86      0.86       858\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_testing11(model)"
      ],
      "metadata": {
        "id": "lJRkgtlk5PXh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce6276f-dbdd-4226-ba99-cb5914a43c17"
      },
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score on UnderSampled Train Data:  0.8406177156177156\n",
            "\n",
            "Confussion Matrix  of UnderSampled Train Data:\n",
            "  [[1618  103]\n",
            " [ 444 1267]] \n",
            "\n",
            "classification_report of UnderSampled Train Data: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.94      0.86      1721\n",
            "           1       0.92      0.74      0.82      1711\n",
            "\n",
            "    accuracy                           0.84      3432\n",
            "   macro avg       0.85      0.84      0.84      3432\n",
            "weighted avg       0.85      0.84      0.84      3432\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvMLDjWT6YZr"
      },
      "source": [
        "##DECISION TREE MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 259,
      "metadata": {
        "id": "nwjRtmDFkFl3"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = DecisionTreeClassifier(criterion = 'entropy',max_depth = 6, random_state=42)"
      ],
      "metadata": {
        "id": "9zdMA8qo8xTR"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = {}\n",
        "for metric_name, metric_func in metrics.items():\n",
        "    scores = cross_val_score(model, X, Y, cv=kfold, scoring=metric_name)\n",
        "    evaluation_results[metric_name] = scores.mean()"
      ],
      "metadata": {
        "id": "QUQb7Y_q826Y"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Evaluation"
      ],
      "metadata": {
        "id": "-fn9UinX9Ady"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for metric_name, score in evaluation_results.items():\n",
        "    print(f\"Mean_{metric_name.capitalize()}: {score}\\n\")"
      ],
      "metadata": {
        "id": "VRW4pg3S80Iw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfbe5252-1203-4784-e06a-916f133920ea"
      },
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean_Accuracy: 0.941025641025641\n",
            "\n",
            "Mean_Precision: 0.9447243749927159\n",
            "\n",
            "Mean_F1_macro: 0.9409942587063445\n",
            "\n",
            "Mean_Recall: 0.9373157587485277\n",
            "\n",
            "Mean_Roc_auc: 0.9792043085926402\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI4m_n09Wg8R"
      },
      "source": [
        "Printing metrices for the best fold"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')\n",
        "best_fold_index = np.argmax(accuracy_scores)"
      ],
      "metadata": {
        "id": "KxNv97IW9KAu"
      },
      "execution_count": 263,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the train and test indices for the best fold"
      ],
      "metadata": {
        "id": "O1dmaSoT9o8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_index, test_index = list(kfold.split(X))[best_fold_index]"
      ],
      "metadata": {
        "id": "lJlhDssL9NTH"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into train and test sets for the best fold"
      ],
      "metadata": {
        "id": "Uf_yZYAO9mmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = X[train_index], X[test_index]\n",
        "Y_train, Y_test = Y[train_index], Y[test_index]"
      ],
      "metadata": {
        "id": "7xEZ8qSo9QOp"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "0LUMeJVn9SUv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "f17a4e81-bbb6-465c-95f3-0a1b748109cc"
      },
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(criterion='entropy', max_depth=6, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=6, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=6, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 266
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_testing1(model)"
      ],
      "metadata": {
        "id": "W9rbCLSn9Why",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "797d649d-d55b-40d3-f2fa-b927bd934f16"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score on UnderSampled Test Data:  0.9522144522144522\n",
            "\n",
            "Confussion Matrix  of UnderSampled Test Data:\n",
            "  [[431  21]\n",
            " [ 20 386]] \n",
            "\n",
            "classification_report of UnderSampled Test Data: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.95       452\n",
            "           1       0.95      0.95      0.95       406\n",
            "\n",
            "    accuracy                           0.95       858\n",
            "   macro avg       0.95      0.95      0.95       858\n",
            "weighted avg       0.95      0.95      0.95       858\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_testing11(model)"
      ],
      "metadata": {
        "id": "YQQjbYmg9YTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e455c90a-5cc4-4902-d8a4-d5dea7437dae"
      },
      "execution_count": 268,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score on UnderSampled Train Data:  0.9493006993006993\n",
            "\n",
            "Confussion Matrix  of UnderSampled Train Data:\n",
            "  [[1616   77]\n",
            " [  97 1642]] \n",
            "\n",
            "classification_report of UnderSampled Train Data: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.95      1693\n",
            "           1       0.96      0.94      0.95      1739\n",
            "\n",
            "    accuracy                           0.95      3432\n",
            "   macro avg       0.95      0.95      0.95      3432\n",
            "weighted avg       0.95      0.95      0.95      3432\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FCAHJoTR8QI7"
      },
      "source": [
        "##RANDOM FOREST MODEL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "0msl-WI7-dKc"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(criterion = 'entropy',max_depth=10, random_state=42)\n"
      ],
      "metadata": {
        "id": "QKceQ-VB-tQV"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = {}\n",
        "for metric_name, metric_func in metrics.items():\n",
        "    scores = cross_val_score(model, X, Y, cv=kfold, scoring=metric_name)\n",
        "    evaluation_results[metric_name] = scores.mean()"
      ],
      "metadata": {
        "id": "r-X_NIfj-wht"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for metric_name, score in evaluation_results.items():\n",
        "    print(f\"Mean_{metric_name.capitalize()}: {score}\\n\")"
      ],
      "metadata": {
        "id": "KmyHpoPQ-zCX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80aed9a7-c99a-41e3-bb58-060ecf202fc4"
      },
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean_Accuracy: 0.95011655011655\n",
            "\n",
            "Mean_Precision: 0.9595455710948476\n",
            "\n",
            "Mean_F1_macro: 0.9500749705083464\n",
            "\n",
            "Mean_Recall: 0.9398919426004128\n",
            "\n",
            "Mean_Roc_auc: 0.9890707450389282\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Printing metrices for the best fold"
      ],
      "metadata": {
        "id": "x6EPnqGd-4FD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')\n",
        "best_fold_index = np.argmax(accuracy_scores)"
      ],
      "metadata": {
        "id": "YZMCtFRR-1j1"
      },
      "execution_count": 273,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get the train and test indices for the best fold"
      ],
      "metadata": {
        "id": "Ra3eoEIr-9nA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_index, test_index = list(kfold.split(X))[best_fold_index]"
      ],
      "metadata": {
        "id": "N1Qen8OP-7Ra"
      },
      "execution_count": 274,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the data into train and test sets for the best fold"
      ],
      "metadata": {
        "id": "zI6FSbiZ_BMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = X[train_index], X[test_index]\n",
        "Y_train, Y_test = Y[train_index], Y[test_index]"
      ],
      "metadata": {
        "id": "vpZ5e3Oh_Eyw"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "KW3UjgL9_G9E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "outputId": "c800f38f-ba29-4011-dae5-daecae1f779e"
      },
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(criterion='entropy', max_depth=10, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-17 {color: black;background-color: white;}#sk-container-id-17 pre{padding: 0;}#sk-container-id-17 div.sk-toggleable {background-color: white;}#sk-container-id-17 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-17 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-17 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-17 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-17 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-17 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-17 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-17 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-17 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-17 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-17 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-17 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-17 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-17 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-17 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-17 div.sk-item {position: relative;z-index: 1;}#sk-container-id-17 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-17 div.sk-item::before, #sk-container-id-17 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-17 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-17 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-17 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-17 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-17 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-17 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-17 div.sk-label-container {text-align: center;}#sk-container-id-17 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-17 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-17\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" checked><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=10, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_testing1(model)"
      ],
      "metadata": {
        "id": "zj27QWoh_ImD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bddc45e5-22e7-49b7-ab35-1c2a1cb64089"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score on UnderSampled Test Data:  0.9545454545454546\n",
            "\n",
            "Confussion Matrix  of UnderSampled Test Data:\n",
            "  [[416  14]\n",
            " [ 25 403]] \n",
            "\n",
            "classification_report of UnderSampled Test Data: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.96       430\n",
            "           1       0.97      0.94      0.95       428\n",
            "\n",
            "    accuracy                           0.95       858\n",
            "   macro avg       0.95      0.95      0.95       858\n",
            "weighted avg       0.95      0.95      0.95       858\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_testing11(model)"
      ],
      "metadata": {
        "id": "Ro5dDD-G_KKR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce874d46-2284-49a9-f8a7-10d1ad62544a"
      },
      "execution_count": 278,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score on UnderSampled Train Data:  0.9857226107226107\n",
            "\n",
            "Confussion Matrix  of UnderSampled Train Data:\n",
            "  [[1712    3]\n",
            " [  46 1671]] \n",
            "\n",
            "classification_report of UnderSampled Train Data: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99      1715\n",
            "           1       1.00      0.97      0.99      1717\n",
            "\n",
            "    accuracy                           0.99      3432\n",
            "   macro avg       0.99      0.99      0.99      3432\n",
            "weighted avg       0.99      0.99      0.99      3432\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##XGBOOST CLASSIFIER MODEL"
      ],
      "metadata": {
        "id": "PefqkjEpCQmo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializie XGBoost Classifier\n",
        "\n"
      ],
      "metadata": {
        "id": "ChlO0nKYBSID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n"
      ],
      "metadata": {
        "id": "4c8Idq3PGG75"
      },
      "execution_count": 279,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = xgb.XGBClassifier()\n"
      ],
      "metadata": {
        "id": "3yHDyu1BBQlZ"
      },
      "execution_count": 280,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = {}\n",
        "for metric_name, metric_func in metrics.items():\n",
        "    scores = cross_val_score(model, X, Y, cv=kfold, scoring=metric_name)\n",
        "    evaluation_results[metric_name] = scores.mean()"
      ],
      "metadata": {
        "id": "ChTlXVpTBVdp"
      },
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for metric_name, score in evaluation_results.items():\n",
        "    print(f\"Mean_{metric_name.capitalize()}: {score}\\n\")"
      ],
      "metadata": {
        "id": "iZUPP83eBZDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85610c0-8a96-484e-d730-7455aa4f3d50"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean_Accuracy: 0.9706293706293707\n",
            "\n",
            "Mean_Precision: 0.9699351929242803\n",
            "\n",
            "Mean_F1_macro: 0.970603516506063\n",
            "\n",
            "Mean_Recall: 0.9715443636505278\n",
            "\n",
            "Mean_Roc_auc: 0.9953969676954696\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')\n",
        "best_fold_index = np.argmax(accuracy_scores)"
      ],
      "metadata": {
        "id": "yMqnT-IYBkur"
      },
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_index, test_index = list(kfold.split(X))[best_fold_index]"
      ],
      "metadata": {
        "id": "Kd3mb6CZBlG3"
      },
      "execution_count": 284,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = X[train_index], X[test_index]\n",
        "Y_train, Y_test = Y[train_index], Y[test_index]"
      ],
      "metadata": {
        "id": "V6nCIFQbBnKH"
      },
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "uZ9CWAWXBuhw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "7bb04de3-2418-4b6c-f9b3-d2ff2f8b13fe"
      },
      "execution_count": 286,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-18 {color: black;background-color: white;}#sk-container-id-18 pre{padding: 0;}#sk-container-id-18 div.sk-toggleable {background-color: white;}#sk-container-id-18 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-18 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-18 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-18 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-18 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-18 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-18 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-18 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-18 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-18 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-18 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-18 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-18 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-18 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-18 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-18 div.sk-item {position: relative;z-index: 1;}#sk-container-id-18 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-18 div.sk-item::before, #sk-container-id-18 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-18 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-18 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-18 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-18 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-18 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-18 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-18 div.sk-label-container {text-align: center;}#sk-container-id-18 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-18 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-18\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
              "              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 286
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_testing1(model)"
      ],
      "metadata": {
        "id": "ENdvUdADBwU0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24eea76c-2fa0-4165-d6de-a3d3504e7579"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score on UnderSampled Test Data:  0.9766899766899767\n",
            "\n",
            "Confussion Matrix  of UnderSampled Test Data:\n",
            "  [[444   8]\n",
            " [ 12 394]] \n",
            "\n",
            "classification_report of UnderSampled Test Data: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.98       452\n",
            "           1       0.98      0.97      0.98       406\n",
            "\n",
            "    accuracy                           0.98       858\n",
            "   macro avg       0.98      0.98      0.98       858\n",
            "weighted avg       0.98      0.98      0.98       858\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_testing11(model)"
      ],
      "metadata": {
        "id": "LUySFUu4B0S_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16aca20-cf68-4791-98c7-1c6b3eda65ec"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score on UnderSampled Train Data:  1.0\n",
            "\n",
            "Confussion Matrix  of UnderSampled Train Data:\n",
            "  [[1693    0]\n",
            " [   0 1739]] \n",
            "\n",
            "classification_report of UnderSampled Train Data: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1693\n",
            "           1       1.00      1.00      1.00      1739\n",
            "\n",
            "    accuracy                           1.00      3432\n",
            "   macro avg       1.00      1.00      1.00      3432\n",
            "weighted avg       1.00      1.00      1.00      3432\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##LIGHT GBM CLASSIFIER MODEL"
      ],
      "metadata": {
        "id": "PPDExHBGCllj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as lgb"
      ],
      "metadata": {
        "id": "GVhVhf_gCuwy"
      },
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = lgb.LGBMClassifier()"
      ],
      "metadata": {
        "id": "YzgXQfvBCvoO"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_results = {}\n",
        "for metric_name, metric_func in metrics.items():\n",
        "    scores = cross_val_score(model, X, Y, cv=kfold, scoring=metric_name)\n",
        "    evaluation_results[metric_name] = scores.mean()"
      ],
      "metadata": {
        "id": "_kbxlJgFCrGq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68a45c06-1259-4c7c-b4da-91ca7640c7aa"
      },
      "execution_count": 291,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 1739, number of negative: 1693\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000267 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1892\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506702 -> initscore=0.026808\n",
            "[LightGBM] [Info] Start training from score 0.026808\n",
            "[LightGBM] [Info] Number of positive: 1711, number of negative: 1721\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001130 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1898\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498543 -> initscore=-0.005828\n",
            "[LightGBM] [Info] Start training from score -0.005828\n",
            "[LightGBM] [Info] Number of positive: 1703, number of negative: 1729\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000285 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1897\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496212 -> initscore=-0.015152\n",
            "[LightGBM] [Info] Start training from score -0.015152\n",
            "[LightGBM] [Info] Number of positive: 1717, number of negative: 1715\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1891\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500291 -> initscore=0.001166\n",
            "[LightGBM] [Info] Start training from score 0.001166\n",
            "[LightGBM] [Info] Number of positive: 1710, number of negative: 1722\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000283 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1894\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498252 -> initscore=-0.006993\n",
            "[LightGBM] [Info] Start training from score -0.006993\n",
            "[LightGBM] [Info] Number of positive: 1739, number of negative: 1693\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000282 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1892\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506702 -> initscore=0.026808\n",
            "[LightGBM] [Info] Start training from score 0.026808\n",
            "[LightGBM] [Info] Number of positive: 1711, number of negative: 1721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000275 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1898\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498543 -> initscore=-0.005828\n",
            "[LightGBM] [Info] Start training from score -0.005828\n",
            "[LightGBM] [Info] Number of positive: 1703, number of negative: 1729\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1897\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496212 -> initscore=-0.015152\n",
            "[LightGBM] [Info] Start training from score -0.015152\n",
            "[LightGBM] [Info] Number of positive: 1717, number of negative: 1715\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000186 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1891\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500291 -> initscore=0.001166\n",
            "[LightGBM] [Info] Start training from score 0.001166\n",
            "[LightGBM] [Info] Number of positive: 1710, number of negative: 1722\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000281 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1894\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498252 -> initscore=-0.006993\n",
            "[LightGBM] [Info] Start training from score -0.006993\n",
            "[LightGBM] [Info] Number of positive: 1739, number of negative: 1693\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000280 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1892\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506702 -> initscore=0.026808\n",
            "[LightGBM] [Info] Start training from score 0.026808\n",
            "[LightGBM] [Info] Number of positive: 1711, number of negative: 1721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1898\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498543 -> initscore=-0.005828\n",
            "[LightGBM] [Info] Start training from score -0.005828\n",
            "[LightGBM] [Info] Number of positive: 1703, number of negative: 1729\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000278 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1897\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496212 -> initscore=-0.015152\n",
            "[LightGBM] [Info] Start training from score -0.015152\n",
            "[LightGBM] [Info] Number of positive: 1717, number of negative: 1715\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000281 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1891\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500291 -> initscore=0.001166\n",
            "[LightGBM] [Info] Start training from score 0.001166\n",
            "[LightGBM] [Info] Number of positive: 1710, number of negative: 1722\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000807 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1894\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498252 -> initscore=-0.006993\n",
            "[LightGBM] [Info] Start training from score -0.006993\n",
            "[LightGBM] [Info] Number of positive: 1739, number of negative: 1693\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000270 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1892\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506702 -> initscore=0.026808\n",
            "[LightGBM] [Info] Start training from score 0.026808\n",
            "[LightGBM] [Info] Number of positive: 1711, number of negative: 1721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000303 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1898\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498543 -> initscore=-0.005828\n",
            "[LightGBM] [Info] Start training from score -0.005828\n",
            "[LightGBM] [Info] Number of positive: 1703, number of negative: 1729\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000291 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1897\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496212 -> initscore=-0.015152\n",
            "[LightGBM] [Info] Start training from score -0.015152\n",
            "[LightGBM] [Info] Number of positive: 1717, number of negative: 1715\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000273 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1891\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500291 -> initscore=0.001166\n",
            "[LightGBM] [Info] Start training from score 0.001166\n",
            "[LightGBM] [Info] Number of positive: 1710, number of negative: 1722\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000815 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1894\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498252 -> initscore=-0.006993\n",
            "[LightGBM] [Info] Start training from score -0.006993\n",
            "[LightGBM] [Info] Number of positive: 1739, number of negative: 1693\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000282 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1892\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506702 -> initscore=0.026808\n",
            "[LightGBM] [Info] Start training from score 0.026808\n",
            "[LightGBM] [Info] Number of positive: 1711, number of negative: 1721\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000296 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1898\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498543 -> initscore=-0.005828\n",
            "[LightGBM] [Info] Start training from score -0.005828\n",
            "[LightGBM] [Info] Number of positive: 1703, number of negative: 1729\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000265 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1897\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496212 -> initscore=-0.015152\n",
            "[LightGBM] [Info] Start training from score -0.015152\n",
            "[LightGBM] [Info] Number of positive: 1717, number of negative: 1715\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000209 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1891\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500291 -> initscore=0.001166\n",
            "[LightGBM] [Info] Start training from score 0.001166\n",
            "[LightGBM] [Info] Number of positive: 1710, number of negative: 1722\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000275 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1894\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498252 -> initscore=-0.006993\n",
            "[LightGBM] [Info] Start training from score -0.006993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for metric_name, score in evaluation_results.items():\n",
        "    print(f\"Mean_{metric_name.capitalize()}: {score}\\n\")"
      ],
      "metadata": {
        "id": "bAZV8ZMYCyxS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e7e2afb-5750-4448-d071-687b5ece9be2"
      },
      "execution_count": 292,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean_Accuracy: 0.9699300699300698\n",
            "\n",
            "Mean_Precision: 0.972439187103039\n",
            "\n",
            "Mean_F1_macro: 0.9699054687782145\n",
            "\n",
            "Mean_Recall: 0.9673640602006246\n",
            "\n",
            "Mean_Roc_auc: 0.995518301517421\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores = cross_val_score(model, X, Y, cv=kfold, scoring='accuracy')\n",
        "best_fold_index = np.argmax(accuracy_scores)"
      ],
      "metadata": {
        "id": "DP-jbolSC_rz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c3fc6a0-a641-4b28-9977-07ab8f4bffa2"
      },
      "execution_count": 293,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 1739, number of negative: 1693\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000238 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1892\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506702 -> initscore=0.026808\n",
            "[LightGBM] [Info] Start training from score 0.026808\n",
            "[LightGBM] [Info] Number of positive: 1711, number of negative: 1721\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000752 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 1898\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498543 -> initscore=-0.005828\n",
            "[LightGBM] [Info] Start training from score -0.005828\n",
            "[LightGBM] [Info] Number of positive: 1703, number of negative: 1729\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1897\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.496212 -> initscore=-0.015152\n",
            "[LightGBM] [Info] Start training from score -0.015152\n",
            "[LightGBM] [Info] Number of positive: 1717, number of negative: 1715\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000184 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1891\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500291 -> initscore=0.001166\n",
            "[LightGBM] [Info] Start training from score 0.001166\n",
            "[LightGBM] [Info] Number of positive: 1710, number of negative: 1722\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000275 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1894\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.498252 -> initscore=-0.006993\n",
            "[LightGBM] [Info] Start training from score -0.006993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_index, test_index = list(kfold.split(X))[best_fold_index]"
      ],
      "metadata": {
        "id": "hCcMaBUEDFqI"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test = X[train_index], X[test_index]\n",
        "Y_train, Y_test = Y[train_index], Y[test_index]"
      ],
      "metadata": {
        "id": "vjrMjRsLDHf0"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "SAfGLRoLDIwy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "5b918db4-cfa1-40a1-953f-0b46f101497e"
      },
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 1739, number of negative: 1693\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000202 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 1892\n",
            "[LightGBM] [Info] Number of data points in the train set: 3432, number of used features: 13\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.506702 -> initscore=0.026808\n",
            "[LightGBM] [Info] Start training from score 0.026808\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-19 {color: black;background-color: white;}#sk-container-id-19 pre{padding: 0;}#sk-container-id-19 div.sk-toggleable {background-color: white;}#sk-container-id-19 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-19 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-19 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-19 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-19 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-19 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-19 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-19 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-19 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-19 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-19 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-19 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-19 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-19 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-19 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-19 div.sk-item {position: relative;z-index: 1;}#sk-container-id-19 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-19 div.sk-item::before, #sk-container-id-19 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-19 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-19 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-19 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-19 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-19 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-19 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-19 div.sk-label-container {text-align: center;}#sk-container-id-19 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-19 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-19\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" checked><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 296
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_testing1(model)"
      ],
      "metadata": {
        "id": "Qqx9V49WDKHh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "398e198a-6f05-43b0-ea0a-92cc2eeb0b9d"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score on UnderSampled Test Data:  0.9731934731934732\n",
            "\n",
            "Confussion Matrix  of UnderSampled Test Data:\n",
            "  [[442  10]\n",
            " [ 13 393]] \n",
            "\n",
            "classification_report of UnderSampled Test Data: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97       452\n",
            "           1       0.98      0.97      0.97       406\n",
            "\n",
            "    accuracy                           0.97       858\n",
            "   macro avg       0.97      0.97      0.97       858\n",
            "weighted avg       0.97      0.97      0.97       858\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_testing11(model)"
      ],
      "metadata": {
        "id": "-oTxc1HCDKaQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84075d0c-62d8-4633-b815-f4d1ecb8697c"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Score on UnderSampled Train Data:  1.0\n",
            "\n",
            "Confussion Matrix  of UnderSampled Train Data:\n",
            "  [[1693    0]\n",
            " [   0 1739]] \n",
            "\n",
            "classification_report of UnderSampled Train Data: \n",
            "\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1693\n",
            "           1       1.00      1.00      1.00      1739\n",
            "\n",
            "    accuracy                           1.00      3432\n",
            "   macro avg       1.00      1.00      1.00      3432\n",
            "weighted avg       1.00      1.00      1.00      3432\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}